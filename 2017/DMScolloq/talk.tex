\documentclass[hide notes,intlimits,usenames,dvipsnames]{beamer}

\mode<presentation>
{
  \usetheme{Singapore}
  \usefonttheme{professionalfonts}
  \setbeamertemplate{blocks}[rounded][shadow=true]
  \setbeamercovered{transparent}
  \setbeamertemplate{footline}[frame number]
}

% load packages
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[multidot]{grffile}
\usepackage{verbatim,empheq}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,shadows}
\usetikzlibrary{decorations.pathreplacing}

\usepackage{animate}
\usepackage{amsmath,verbatim}

\usepackage[noend]{algpseudocode}
\usepackage{listings}

% see http://tex.stackexchange.com/questions/86188/labelling-with-arrows-in-an-automated-way

\newif\ifclipme\clipmetrue
\tikzset{labelstyle/.style={LabelStyle/.append style={#1}},linestyle/.style={LineStyle/.append style={#1}}}
\tikzset{LabelStyle/.initial={},LineStyle/.initial={}}

\newcommand{\mathWithDescription}[4][]{{%
    \tikzset{#1}%
    \tikz[baseline]{
        \node[draw=red,rounded corners,anchor=base] (m#4) {$\displaystyle#2$};
        \ifclipme\begin{pgfinterruptboundingbox}\fi
            \node[above of=m#4,font=\strut, LabelStyle] (l#4) {#3};
            \draw[-,red, LineStyle] (l#4) to (m#4);
        \ifclipme\end{pgfinterruptboundingbox}\fi
    }%
}}

\newcommand{\mathWithDescriptionStarred}[3][]{{%
    \clipmefalse%
    \mathWithDescription[#1]{#2}{#3}{\themathLabelNode}%
}}

\newcounter{mathLabelNode}

\newcommand{\mathLabelBox}[3][]{%
   \stepcounter{mathLabelNode}%
   \mathWithDescription[#1]{#2}{#3}{\themathLabelNode}%
   \vphantom{\mathWithDescriptionStarred[#1]{#2}{#3}{\themathLabelNode}}%
}

\definecolor{dark red}{HTML}{E41A1C}
\definecolor{dark green}{HTML}{4DAF4A}
\definecolor{dark violet}{HTML}{984EA3}
\definecolor{dark blue}{HTML}{084594}
\definecolor{dark orange}{HTML}{FF7F00}
\definecolor{light blue}{HTML}{377EB8}
\definecolor{light red}{HTML}{FB9A99}
\definecolor{light violet}{HTML}{CAB2D6}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\Kcal}{\mathcal{K}}
\newcommand{\Xcal}{\mathcal{X}}

\newcommand{\bF}{\mathbf{F}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bX}{\mathbf{X}}

\newcommand{\bb}{\mathbf{b}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}

\newcommand{\Div}{\nabla\cdot}
\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lap}{\triangle}
\renewcommand{\bar}{\overline}

\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}


\newenvironment{transbox}[1][]{%
\begin{tikzpicture}
\node[drop shadow,rounded corners,text width=\textwidth,fill=white, fill opacity=#1,text opacity=1] \bgroup
}{
\egroup;\end{tikzpicture}}


\title{Optimal solvers for partial differential equations}

\author[Bueler]{Ed Bueler}

\institute[UAF]{
  \scriptsize Dept of Mathematics and Statistics and Geophysical Institute \\

  University of Alaska Fairbanks
}

%\titlegraphic{\includegraphics[width=\textwidth]{andycoast.png}}

\beamertemplatenavigationsymbolsempty   % remove faint and silly navigation symbols at bottom
\renewcommand{\insertnavigation}[1]{}   % remove section headings from top of each slide

\setbeamerfont{date}{size=\scriptsize}
\date{}

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    %\tableofcontents[currentsection,hideallsubsections]
    \tableofcontents[currentsection]
  \end{frame}
}


\begin{document}

%\graphicspath{{../../old/commonfigs/}}

\begin{frame}
    \vspace{10mm}
    \titlepage
    \begin{center}
    \tiny DMS Colloquium \quad 28 November, 2017
    \end{center}
\end{frame}

%\begin{frame}
%    \frametitle{Outline}
%    \tableofcontents
%\end{frame}


\section{how to approximately solve a PDE}

\begin{frame}{Poisson equation}

\begin{itemize}
\item for much of this talk I'll use two example PDE problems

\bigskip
\item[\textbf{1.}] \emph{Poisson equation} with Dirichlet boundary conditions:
	    $$- \grad^2 u = f \qquad \text{ on } \Omega \subset \RR^d \text{ with } u\big|_{\partial \Omega} = g,$$
    \vspace{-5mm}
	\begin{itemize}
	\item[$\circ$] a linear elliptic PDE problem in dimension $d=2$ or $d=3$
	\item[$\circ$] recall that $\grad^2 u = \Div \left(\grad u\right) = u_{xx}+u_{yy}+u_{zz}$
	\item[$\circ$] source $f(x,y,z)$ given
	\item[$\circ$] boundary values $g(x,y,z)$ given
	\item[$\circ$] will use various domains $\Omega$ including a square, a cube, and
		\begin{itemize}
        \item a snowflake fractal \hspace{0.3in} \begin{tikzpicture}[scale=0.8,baseline] \input{tikz/snowflake.tex} \end{tikzpicture}
        \end{itemize}
	\item[$\circ$] the solution $u(x,y,z)$ of $- \grad^2 u = 1$ with $g=0$ gives the expected time for a Brownian motion to first hit $\partial\Omega$
	\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{minimal surface equation}

\begin{itemize}
\item[\textbf{2.}] \emph{minimal surface equation (MSE)} with Dirichlet b.c.s:
	    $$- \grad\cdot \left(\frac{\grad u}{\sqrt{1 + |\grad u|^2}}\right) = 0  \qquad \text{ with } u\big|_{\partial \Omega} = g.$$
    \vspace{-2mm}
	\begin{itemize}
	\item[$\circ$] a nonlinear elliptic PDE in 2D
	\item[$\circ$] here: square domain $\Omega = [0,1] \times [0,1]$
	\item[$\circ$] the solution $u(x,y)$ gives the height of a zero-gravity soap bubble which spans a wire frame with height $z=g(x,y)$:
	\end{itemize}

\begin{center}
\begin{tikzpicture}[scale=1.6]
  \draw[->,gray,very thin] (0.0,0.0) -- (1.2,0.0) node[below] {$x$};
  \draw[->,gray,very thin] (0.0,0.0) -- (-0.75,0.75) node[left] {$y$};
  \draw[line width=1.0pt] (0.0,0.0) -- (1.0,0.0) -- (0.45,0.55) -- (-0.55,0.55) -- (-0.275,0.5) -- cycle;
\end{tikzpicture}
\end{center}
\end{itemize}
\end{frame}


\begin{frame}{today's talk: mostly elliptic PDEs}

both examples {\color{Blue} \textbf{1}} \& {\color{Blue} \textbf{2}}
\begin{itemize}
\item are well-posed elliptic PDE BVPs
\item seek solution $u$ from an \alert{$\infty$-dimensional vector space}
\end{itemize}

\bigskip\bigskip

\scriptsize
technical/expert comments:
\begin{itemize}
\item both examples derivable from variational principles, thus well-posed
\item the ``$\infty$-dimensional vector space'' is a Sobolev space such as $H^1(\Omega)$
\item \emph{numerically}, nonlinear elliptic PDE BVPs are representative of the hardest class of PDE problems because they arise as the time-step problems in the (harder) stiff time-dependent case
\item \dots but smoothness of the solution matters \emph{a lot} to numerical difficulty
\end{itemize}
\end{frame}


\begin{frame}{approximation: finite difference method}
\begin{itemize}
\item \emph{main idea}: a PDE BVP is a system of $\infty$ eqns in $\infty$ unknowns
\item some problems can be solved exactly
	\begin{itemize}
	\item[$\circ$] \emph{example}.  $u(x,y)=x^2-y^2$ solves $\grad^2 u = 0$
	\end{itemize}
\item most problems are not solved exactly, so we
	\begin{itemize}
	\item[$\circ$] \alert{approximate by $N$ equations in $N$ unknowns}
	\item[$\circ$] \dots \, where $N \ll \infty$
	\end{itemize}
\item one method is \emph{finite differences} (FDM), based on
	    $$f'(x) = \lim_{h \to 0} \frac{f(x+h)-f(x)}{h} \approx \frac{f(x+h)-f(x)}{h}$$
\item as used for the 2D Poisson equation:
	    $$u_{xx}+u_{yy} \approx \frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4 u_{ij}}{h^2}$$
\end{itemize}
\end{frame}


\begin{frame}{structured grids}
\begin{itemize}
\item for a much of this talk I'll use \emph{structured grids}
	\begin{itemize}
	\item[$\circ$] i.e.~products of grids in 1D
	\end{itemize}
\item a sequence of such grids $\Omega^{(k)}$; the \emph{level} $k$ grid has
	\begin{itemize}
	\item[$\circ$] equal spacing $h_k$ in each direction
    \item[$\circ$] $N_k = O(h_k^{-d})$ points in $d$ dimensions
	    \begin{itemize}
	    \item typically: $N_{k+1} = 2^d N_k$
	    \end{itemize}
	\end{itemize}

\bigskip
\input{tikz/fourlevelsofgrids.tex}

\medskip
\item ``increasing resolution'' or ``refinement'' means $h_k \to 0$
\end{itemize}
\end{frame}


\begin{frame}{approximation: finite element method (FEM)}
\begin{itemize}
\item this discretization uses the \emph{weak form} of the PDE
\item example: the weak form for the Poisson equation is
    $$\int_\Omega \grad u \cdot \grad v = \int_\Omega f v \qquad \forall v \in H_0^1(\Omega)$$
    \vspace{-4mm}
	\begin{itemize}
	\item[$\circ$] derivation: multiply PDE by $v$ and integrate by parts
	\end{itemize}
\item well-suited to unstructured meshes of arbitrary polygonal/polyhedral domains
	\begin{itemize}
	\item[$\circ$] e.g.~triangulate the snowflake:
	\end{itemize}

\begin{center}
\begin{tikzpicture}[scale=1.3,baseline] \input{tikz/snowflake.tex} \end{tikzpicture}
\qquad $\to$ \qquad
\begin{tikzpicture}[scale=1.3,baseline] \input{tikz/meshedsnowflake.tex} \end{tikzpicture}
\end{center}

\footnotesize
\item \alert{Fall 2018: graduate seminar in FEM}
\end{itemize}
\end{frame}


\begin{frame}{finite element method}

in more detail, the FEM uses
\begin{itemize}
\item a {\footnotesize triangular/quadrilateral/tetrahedral/etc.}~mesh of $N$ nodes on $\Omega$
\item an $N$-dimensional subspace $\mathcal{X} \subset H^1(\Omega)$ with basis $\{\psi_j\}$ of
\item \begin{minipage}[t]{50mm}
\dots \emph{hat functions} $\psi_j$ which are zero at all $N$ nodes of the mesh except the $j$th where it's one
\end{minipage}
\qquad
\begin{minipage}[t]{40mm}
\vspace{-4mm}
\begin{tikzpicture}[scale=0.6, z={(.707,.3)}, baseline]
\input{tikz/hatfunction.tex}
\end{tikzpicture}
\end{minipage}
\end{itemize}

\vspace{-3mm}
then the FEM
\begin{itemize}
\item supposes
   $$u(x,y) = \sum_j u_{j}\, \psi_{j}(x,y)$$
for $u_j\in \RR$ ($N$ unknowns)
\item and requires the weak form to hold for all $v=\psi_i$ ($N$ eqns)
\end{itemize}

\medskip
which yields a system of $N$ eqns in $N$ unknowns
\end{frame}


\begin{frame}{linear systems with sparse matrices}
\begin{itemize}
\item both methods (FDM and FEM) produce \emph{sparse matrices}
\item for example, the Poisson equation becomes a linear system
    $$A \bu = \bb$$
    \vspace{-4mm}
	\begin{itemize}
	\item[$\circ$] $A\in\RR^{N\times N}$ is sparse
	\item[$\circ$] $A$ is symmetric positive definite (SPD)
	\end{itemize}
\item the nonlinear MSE produces such a linear system at each Newton step (\emph{more later})
\item \emph{pro tip}: Matlab's \texttt{spy(A)} shows nonzero structure
\end{itemize}

\bigskip
\begin{center}
\includegraphics[width=0.85\textwidth]{figs/spythree}

\scriptsize
Poisson 1D (either method) \quad MSE FDM 2D square \qquad Poisson FEM 2D snowflake

\end{center}
\end{frame}


\begin{frame}{sparse matrices have cheap mat-vec}

if
\begin{itemize}
\item $A$ is $N\times N$ and sparse, and
\item number of nonzeros per row is bounded independently of $N$
\end{itemize}
then
\begin{quote}
the work of computing $A \bv$ is $O(N)$
\end{quote}

\begin{itemize}
\item computing $A \bv$ is called a ``mat-vec''
\item the ``bounded'' condition is automatic for structured grids
\item for unstructured triangulations and FEM
   $$\text{(nonzeros in row } j) = \operatorname{degree}(\text{node } j) + 1$$
so cost of $A\bv$ is $O((\max \operatorname{degree}) N)$
\end{itemize}

\bigskip
\begin{center}
\includegraphics[width=0.5\textwidth]{figs/spythree}

\tiny

\qquad $3$ \qquad\qquad\qquad\qquad $9$ \qquad\qquad\quad $\max \operatorname{degree} + 1$
\end{center}
\end{frame}


\section{what is an ``optimal solver''?}

\begin{frame}{define ``optimal''}
\begin{itemize}
\item consider $N$ equations in $N$ unknowns: \qquad $\mathbf{F}(\mathbf{u}) = 0$
	\begin{itemize}
	\item[$\circ$] $\mathbf{F}:\RR^N \to \RR^N$, the \emph{residual}, is generally nonlinear
	\item[$\circ$] $\mathbf{F}(\mathbf{w}) = \mathbf{b} - A \mathbf{w}$ in the linear case
	\end{itemize}

\bigskip
\noindent \textbf{definition.}  \begin{minipage}[t]{80mm}
an algorithm which solves $\mathbf{F}(\mathbf{u}) = 0$ is \alert{\emph{optimal}} if it does $O(N)$ or $O(N\log N)$ work
\end{minipage}

\bigskip \bigskip
\item if you have ever tried solving big, nontrivially-coupled systems of equations, you'll conclude optimality is generally hopeless
\end{itemize}
\end{frame}


\begin{frame}{slide full of caveats}

in the definition ``an algorithm which solves $\mathbf{F}(\mathbf{u}) = 0$ is \emph{optimal} if it does $O(N)$ or $O(N\log N)$ work,''
\begin{itemize}
\item  ``solves'' means that it generates $\mathbf{u}_n$ so that $\frac{\|\mathbf{F}(\mathbf{u}_n)\|}{\|\mathbf{F}(\mathbf{u}_0)\|} \le \text{tol}$ where $\mathbf{u}_0$ is an initial guess
	\begin{itemize}
	\item[$\circ$] in linear case $A\bu=\bb$, given any rounding error, only $O(\kappa(A)\eps_{\text{mach}})$ accuracy is possible anyway\footnote{for students of MATH 614}
	\end{itemize}
\item ``work'' $=$ (count of floating point operations)
	\begin{itemize}
	\item[$\circ$] \emph{or} time for the algorithm to run, but timing on modern computers is really messy
	\end{itemize}
\item ``$O(\dots)$'' hides a constant which may depend on tol but may not depend on $N$
\item a nearly-equivalent definition could say ``work is less than $O(N^{1+\delta})$ for any $\delta>0$''
\end{itemize}
\end{frame}


\begin{frame}{example: solving tridiagonal matrices}
\begin{itemize}
\item an easy example of optimality is for tridiagonal matrices
\item Gauss elimination without pivoting\footnote{a.k.a.~the \emph{Thomas algorithm}} solves $A \bu = \bb$ in $8N-6=O(N)$ operations
	\begin{itemize}
	\item[$\circ$] strictly diagonally-dominant suffices to avoid pivoting
	\end{itemize}
\item for SPD tridiagonal matrices, use \emph{banded Cholesky decomposition}, again $O(N)$
\item also applies to pentadiagonal, septadiagonal, \dots
\item thus 1D Poisson problem \, $-u''=f$ \, has optimal solution method 
\end{itemize}

\bigskip
\begin{center}
\includegraphics[width=0.2\textwidth]{figs/spytri}
\end{center}
\end{frame}


\begin{frame}{non-example:  banded direct methods in 2D,3D}
\begin{itemize}
\item for structured-grid FDM method on PDEs in 2D and 3D the bandwidth of $A$ grows as $h\to 0$
\item for example, for MSE on $\Omega=[0,1]\times[0,1]$:

\begin{center}
\begin{tikzpicture}[scale=1.6,baseline] \input{tikz/unitsquaregridordering.tex} \end{tikzpicture} \qquad \begin{minipage}[b]{5mm} $\to$ \vspace{10mm} \end{minipage} \qquad \includegraphics[width=0.19\textwidth]{figs/spybanded}
\end{center}

\item if $N\times N$ matrix $A$ has bandwidth $p$ then banded Cholesky does $O(N p^2)$ work
\item thus for direct methods for PDE problems on structured grids with $m$ points in each direction:
	\begin{itemize}
	\item[$\circ$] $N=m^2$ and $p=m$ so $O(N^2)$ work in 2D
	\item[$\circ$] $N=m^3$ and $p=m^2$ so $O(N^{7/3})$ work in 3D
	\end{itemize}
\item variable reordering helps a lot \dots but not enough
\end{itemize}
\end{frame}


\begin{frame}{Krylov methods}
\begin{itemize}
\item $\text{A New Hope}^{\includegraphics[width=0.06\textwidth]{figs/anewhope}}$ in the 1970s among numerical analysts, for FDM and FEM discretizations of a PDE, emphasized that

\begin{quote}
given $\mathbf{w}\in\RR^N$, evaluating $\mathbf{F}(\mathbf{w})$ requires $O(N)$ work
\end{quote}

\item FIXME    \includegraphics[width=0.2\textwidth]{figs/krylov}
\end{itemize}
\end{frame}


\begin{frame}{rate of convergence of CG}
\begin{itemize}
\item FIXME
\end{itemize}
\end{frame}


\begin{frame}{tangent: spectral methods}
\begin{itemize}
\item FIXME
\item spectral methods show that pursuit of optimality is \emph{not} the only good goal
\end{itemize}
\end{frame}


\section{multigrid}

\begin{frame}{multigrid: what it does}

\small
\begin{itemize}
\item given structured grids $\left\{\Omega^{(j)}\right\}_0^k$
\item given initial guess $\bu_0$ on the finest grid $\Omega^{(k)}$
\item basic multigrid cycle to solve $A \bu = \bb$ is $\text{\textsc{Vcycle}}(\bu_0,k)$:

\medskip
\begin{algorithmic}
\footnotesize
\Function{Vcycle}{$\bw,l$}
    \If{$l == 0$}
        \State solve $A \bv = \bb$, e.g.~by a direct solver
    \Else
        \State improve $\bw$ on the level $l$ grid, giving $\bv$
        \State compute residual $\br = \bb - A \bv$
        \State restrict $\br$ to level $l-1$, giving $\br^C$
        \State $\bz^C = \text{\textsc{Vcycle}}(0,l-1$)
        \State $\bv \gets \bv + (\text{interpolate } \bz^C \text{ to level $l$ grid})$
        \State improve $\bv$ some more on the level $l$ grid
        \EndIf
    \Return $\bv$
\EndFunction
\end{algorithmic}
\end{itemize}
\end{frame}


\begin{frame}{multigrid V-cycles}

\begin{itemize}
\item FIXME
\end{itemize}

\input{tikz/vwcycles.tex}


\medskip
\qquad \input{tikz/fourlevelsofgrids.tex}
\end{frame}


\begin{frame}{multigrid: why it works}
\begin{itemize}
\item FIXME
\end{itemize}
\end{frame}


\begin{frame}{algebraic multigrid}
\begin{itemize}
\item FIXME   \includegraphics[width=0.2\textwidth]{figs/urschel}
\end{itemize}
\end{frame}


\begin{frame}{an optimality lemma}

conditions under which multgrid cycles as preconditioners for CG give optimal solver
\begin{itemize}
\item FIXME
\end{itemize}
\end{frame}


\section{nonlinear problems and unstructured grids}

\begin{frame}{wider applicability of multigrid}

\begin{columns}
\begin{column}{0.8\textwidth}
\begin{itemize}
\item multigrid was invented for Poisson and linear elliptic equations by Federenko (1962, 1964)
\item apparently, by 1975 optimism about multigrid was limited to one person: Achi Brandt
\item faith in its wider applicability has been growing every since
\end{itemize}
\end{column}

\begin{column}{0.15\textwidth}

\includegraphics[width=\textwidth]{figs/starwars-achi-mashup.jpg}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{FIXME}
\begin{itemize}
\item FIXME
\end{itemize}
\end{frame}



\section{barriers to optimality}


\begin{frame}{low regularity of solution}
\begin{itemize}
\item again assume solution of (nonlinear) BVP on $\Omega \subset \RR^d$
\item $W(h)$ Newton iterations
\item $K(h)$ preconditioned Krylov steps per Newton
\item FIXME  in some case number of Newton steps (or Krylov steps) now grows as $h\to 0$
\item can demo w MSE  \includegraphics[width=0.4\textwidth]{figs/rayleigh-taylor-instability}
\end{itemize}
\end{frame}


\begin{frame}{constrained problems}
\begin{itemize}
\item FIXME  number of Newton steps proportional to $D/h$ where $D$ is distance-to-move free boundary
\item Max working on it
\end{itemize}
\end{frame}


\begin{frame}{initial/boundary value problems}

\begin{itemize}
\item problem posed on $\Omega \times [0,T]$ where $\Omega \subset \RR^d$
    \begin{itemize}
    \item[$\circ$] example: nonlinear convection/diffusion/reaction equation
      $$u_t = \Div(a(u) \grad u) - b(u)\cdot \grad u + f(u)$$
    \item[$\circ$] evolution problem with states in some $W_k^p(\Omega)$
    \end{itemize}
\item for these problems there's no intrinsic ``barrier'' \dots
\item rather a lack of clarity about what ``optimal'' should mean
\end{itemize}
\end{frame}


\begin{frame}{numerical parameters for IBVPs}

\begin{itemize}
\item assume structured grid: $h=\Delta x = \Delta y=\Delta z$
    \begin{itemize}
    \item[$\circ$] $N=$ (spatial degrees of freedom) $=O(h^{-d})$
    \end{itemize}
\item time step is limited in some way \dots almost always:
    $$\Delta t \le O(h^q)$$
    \vspace{-5mm}
    \begin{itemize}
    \item[$\circ$] stability: $q=2$ for explicit schemes on diffusions
	    \begin{itemize}
	    \item explicit schemes clearly not optimal
	    \end{itemize}
    \item[$\circ$] accuracy: usually $q=1$
	    \begin{itemize}
	    \item e.g.~for $O(h^2+\Delta t^2)$ methods
	    \end{itemize}
    \item[$\circ$] movie: generate $M$ frames, so $\Delta t = T/M$
    \item[$\circ$] ``total number of degrees of freedom'' $=M N$?
    \end{itemize}
\item (implicit) solution for one time step using NK:
    \begin{itemize}
    \item[$\circ$] $W(h)$ Newton iterations
    \item[$\circ$] $K(h)$ preconditioned Krylov steps per Newton
    \item[$\circ$] $W(h)=K(h)=1$ for explicit methods
    \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{optimality(?) for IBVPs}

\begin{itemize}
\item yields: a ``performance model'' for solving IBVPs on $\Omega \times [0,T]$
\item cost of computation:
\footnotesize
\begin{align*}
C &= (\text{number of steps}) \cdot (\text{iterations per step}) \cdot (\text{cost of 1 spatial residual}) \\
  &= O(h^{-q}) \cdot W(h) \, K(h) \cdot O(h^{-d})
\end{align*}
\normalsize
\item we define solver to be \emph{optimal} if work is $O(MN)$?
    \begin{itemize}
    \item[$\circ$] optimal movie-limited (implicit) steps:
        $$C = M \cdot W \cdot O(1) \cdot O(h^{-d}) = O(MN)$$
    \item[$\circ$] optimal accuracy-limited (implicit) steps:
        $$C = O(h^{-1}) \cdot W \cdot O(1) \cdot O(h^{-d}) = O(N^{1+1/d})$$
    \item[$\circ$] explicit:
        $$C = O(h^{-2}) \cdot 1 \cdot 1 \cdot O(h^{-d}) = O(N^{1+2/d}) \hfill \alert{\leftarrow \text{ beat this!?}}$$
    \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{goal of parallel scaling}
\begin{itemize}
\item FIXME not exactly a ``barrier'' but a conflict
\end{itemize}
\end{frame}


\begin{frame}{conclusion}
\begin{itemize}
\item as you head toward $N=\infty$, in approximately solving your PDE-type problem on a modern computer,

\bigskip
\begin{quote}
\alert{you should be able to solve $N$ equations in $N$ unknowns in $O(N)$ time}
\end{quote}

\bigskip
\item it is a good goal, anyway
\end{itemize}
\end{frame}


\end{document}
